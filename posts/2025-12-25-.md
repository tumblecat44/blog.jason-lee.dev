---
title: "크리스마스"
date: "2025-12-25"
---

즐거운 크리스마스가 찾아왔다.

하지만 별로 한 거는 없어서 그냥 좋은 휴일이라고 느껴진다.

크리스마스와 별개로 AI Agent 와 LLM 모델에 대한 생각을 했다.

나는 GPT 를 제일 많이 썼었다. 하지만 요즘은 Gemini 를 가장 많이 쓴다. Flash 와 Pro 로 모델이 나눠져있다는 것 자체가 매력적이고 구글과 네이티브로 연결되어있어 타 LLM 서비스 대비 검색이 압도적으로 빠르고 할루시네이션이 거의 없기 때문이다.
내 마음 속에 있던 GPT의 선점효과를 깨부술정도로 Gemini 가 똑똑하다.

순수 LLM 의 성능과 추론이 기존에는 생각도 못했을 만큼 좋아졌다. 기존에 LangChain, LangGraph 를 사용해서 AI Agent 를 만드는 것의 비효율성이 높아지고 있다고 생각한다.
나는 AI Agent 가 추론하고 계획을 세우는게 멋있어서 ReAct 나 Plan And Execute 를 직접 구현해볼 목적으로 Sync 에 AI Agent 를 넣었다. GPT 와 Claude API 를 사용했는데 모델 기본의 응답 시간과 더불어 Native 적이지 않은 추론 단계로 인해 AI Agent 의 응답 시간이 많이 느렸었다. 
지금 다시 Sync 의 AI, DeepSync 를 개발한다고 하면 그냥 Gemini 에 MCP 붙일꺼다. 

Gemini 의 장점을 이렇게 말한 이유는 Gemini 에 꽃혀서 새로운 서비스를 만들어보고 싶기 때문이다.
뭘 만들지는 모르겠지만 UX 적으로 Gemini 3.0 Flash 의 응답 속도는 내 가슴을 뛰게 하는 속도 이기 때문에 아무리 쓸 데 없는 서비스를 만들어도 응답속도 하나로 뛰어난 서비스를 만들었다고 느낄 것 같다.

뭐를 만들지는 모르겠지만 세상을 바꿀 소프트웨어를 만들 것이다.
Let's go~~

